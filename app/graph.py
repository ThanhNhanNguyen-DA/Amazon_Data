from langgraph.graph import StateGraph, END
from app.tools import (
    AgentState, 
    search_fashion_tool, 
    recommend_outfit_tool, 
    generate_stylist_answer,
    search_books_tool
)
from langchain_community.chat_models import ChatOllama
from langchain_google_genai import ChatGoogleGenerativeAI
import logging

# C·∫•u h√¨nh Log ƒë·ªÉ d·ªÖ debug
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# -----------------------------
# C√ÅC NODES (NH√ÇN VI√äN)
# -----------------------------

def translate_input_node(state: AgentState):
    """
    Node 1: X·ª≠ l√Ω Ng√¥n ng·ªØ & Ph√¢n lo·∫°i √ù ƒë·ªãnh (Router).
    Th·ª© t·ª±: D·ªãch -> Ph√¢n lo·∫°i.
    """
    logger.info("---NODE: X·ª≠ l√Ω Ng√¥n ng·ªØ & Router---")
    question = (state.get("question") or "").strip()
    
    # M·∫∑c ƒë·ªãnh n·∫øu kh√¥ng c√≥ input
    if not question:
        return {"question_en": "", "category_intent": "fashion"}
    
    # llm = ChatOllama(model="llama3", temperature=0)
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
    
    # -----------------------------------------
    # B∆Ø·ªöC 1: D·ªäCH THU·∫¨T (T·∫°o ra question_en)
    # -----------------------------------------
    trans_prompt = f"""
    You are a smart translator.
    Input text: "{question}"
    
    Logic:
    1. IF input is Vietnamese -> Translate to English.
    2. IF input is English -> Keep it exactly as is.
    
    Output ONLY the final English text. No explanations.
    """
    
    try:
        res = llm.invoke(trans_prompt)
        question_en = res.content.strip().strip('"').strip("'")
    except Exception as e:
        logger.error(f"L·ªói d·ªãch: {e}")
        question_en = question # Fallback d√πng ti·∫øng Vi·ªát lu√¥n
        
    logger.info(f"üëâ Input: {question} -> EN: {question_en}")

    # -----------------------------------------
    # B∆Ø·ªöC 2: PH√ÇN LO·∫†I (D√πng question_en ƒë√£ c√≥)
    # -----------------------------------------
    router_prompt = f"""
    Classify the user intent based on this query: "{question_en}"
    
    Options:
    - "book": if asking about books, authors, reading, novels.
    - "fashion": if asking about clothes, shoes, style, outfit.
    - "general": otherwise.
    
    Output ONLY one word: book OR fashion OR general.
    """
    
    try:
        intent_res = llm.invoke(router_prompt)
        intent = intent_res.content.strip().lower()
        
        # L√†m s·∫°ch output (ph√≤ng tr∆∞·ªùng h·ª£p LLM n√≥i d√†i d√≤ng)
        if "book" in intent: category = "book"
        elif "fashion" in intent: category = "fashion"
        else: category = "fashion" # M·∫∑c ƒë·ªãnh an to√†n
        
    except Exception as e:
        logger.error(f"L·ªói Router: {e}")
        category = "fashion"
    
    logger.info(f"üëâ Router Decision: {category.upper()}")
    
    return {"question_en": question_en, "category_intent": category}
    
def search_node(state: AgentState):
    """Node 2: T√¨m ki·∫øm (ƒêa ng√†nh h√†ng)"""
    intent = state.get("category_intent", "fashion")
    
    if intent == "book":
        logger.info("---NODE: T√¨m ki·∫øm S√ÅCH---")
        products = search_books_tool(state)
    else:
        logger.info("---NODE: T√¨m ki·∫øm TH·ªúI TRANG---")
        products = search_fashion_tool(state)
    
    return {"recommendations": products}


def recommendation_node(state: AgentState):
    """Node 3: G·ª£i √Ω mua k√®m (Collaborative Filtering) ƒëa ng√†nh h√†ng."""
    
    # 1. L·∫•y √ù ƒë·ªãnh (Book hay Fashion?) t·ª´ State (ƒë√£ ƒë∆∞·ª£c Router x√°c ƒë·ªãnh tr∆∞·ªõc ƒë√≥)
    intent = state.get("category_intent", "fashion")
    
    # Log ƒë·ªÉ debug xem h·ªá th·ªëng ƒëang ch·∫°y nh√°nh n√†o
    if intent == 'book':
        logger.info("---NODE: G·ª£i √Ω S√ÅCH mua k√®m---")
    else:
        logger.info("---NODE: G·ª£i √Ω TH·ªúI TRANG ph·ªëi ƒë·ªì---")

    current_recs = state.get("recommendations", [])
    
    # Chi·∫øn thu·∫≠t: L·∫•y s·∫£n ph·∫©m ƒë·∫ßu ti√™n t√¨m th·∫•y (gi·ªëng nh·∫•t) ƒë·ªÉ l√†m g·ªëc g·ª£i √Ω
    if current_recs:
        top_product_id = current_recs[0]['id']
        
        # 2. G·ªçi tool v·ªõi tham s·ªë product_type
        # H√†m n√†y s·∫Ω t·ª± ƒë·ªông ch·ªçn b·∫£ng 'books_index' ho·∫∑c 'fashion_clip_index' d·ª±a tr√™n intent
        outfit_items = recommend_outfit_tool(top_product_id, product_type=intent)
        
        # G·ªôp v√†o danh s√°ch hi·ªán c√≥ (tr√°nh tr√πng l·∫∑p ID)
        existing_ids = {p['id'] for p in current_recs}
        for item in outfit_items:
            if item['id'] not in existing_ids:
                current_recs.append(item)
        
    return {"recommendations": current_recs}

def generate_answer_node(state: AgentState):
    """Node 4: Sinh c√¢u tr·∫£ l·ªùi t∆∞ v·∫•n (B·∫±ng Ti·∫øng Anh)."""
    logger.info("---NODE: Sinh c√¢u tr·∫£ l·ªùi (EN)---")
    
    # H√†m n√†y tr·∫£ v·ªÅ text ti·∫øng Anh (do prompt trong tools.py vi·∫øt b·∫±ng ti·∫øng Anh)
    ans_en = generate_stylist_answer(state)
    return {"answer_en": ans_en}

def translate_output_node(state: AgentState):
    """
    Node 5: Lu√¥n d·ªãch c√¢u tr·∫£ l·ªùi v·ªÅ Ti·∫øng Vi·ªát (Theo y√™u c·∫ßu c·ªßa b·∫°n).
    """
    logger.info("---NODE: D·ªãch Output (EN -> VI)---")
    ans_en = state.get("answer_en", "")
    
    if not ans_en:
        return {"answer_vi": "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin."}

    # llm = ChatOllama(model="llama3", temperature=0)
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0)
    
    # Prompt √©p bu·ªôc tr·∫£ v·ªÅ Ti·∫øng Vi·ªát
    prompt = f"""
    Translate the following response into natural, polite Vietnamese (like a helpful shop assistant).
    
    English Content: "{ans_en}"
    
    Vietnamese Translation:
    """
    
    try:
        res = llm.invoke(prompt)
        ans_vi = res.content.strip()
    except Exception as e:
        logger.error(f"L·ªói d·ªãch output: {e}")
        ans_vi = ans_en 
        
    return {"answer_vi": ans_vi}

# -----------------------------
# X√ÇY D·ª∞NG GRAPH
# -----------------------------
def build_fashion_graph():
    workflow = StateGraph(AgentState)
    
    # 1. Th√™m c√°c node v√†o ƒë·ªì th·ªã
    workflow.add_node("translate_input", translate_input_node)
    workflow.add_node("search", search_node)
    workflow.add_node("recommend", recommendation_node)
    workflow.add_node("generate_answer", generate_answer_node)
    workflow.add_node("translate_output", translate_output_node) # <-- Node m·ªõi
    
    # 2. N·ªëi d√¢y (Edges) - Quy tr√¨nh tu·∫ßn t·ª±
    workflow.set_entry_point("translate_input")
    
    workflow.add_edge("translate_input", "search")
    workflow.add_edge("search", "recommend")
    workflow.add_edge("recommend", "generate_answer")
    workflow.add_edge("generate_answer", "translate_output") # <-- N·ªëi sang d·ªãch
    workflow.add_edge("translate_output", END) # <-- K·∫øt th√∫c sau khi d·ªãch
    
    return workflow.compile()